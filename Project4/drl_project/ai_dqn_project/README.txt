5.2

If using epsilon greedy exploration, what happens when epsilon is set very low (say 0.05) from the start of training? 

What happens when epsilon is set very high (say 0.95) and never decreased? Plot the learning curves from both runs. 


5.3

For a couple states, look at the Q-values that your trained network predicts. Do they appear accurate? 

Suppose they are not accurate, what property must the set of Q-values have in order for the optimal actions to still be chosen?
